[general]
experiment_series = Transfer learning PTB-XL
question = can transfer learning help to improve model performance?
hypothesis = better performance
remarks = Fine-tuning transferred model on kerckhoff data

[environment]
gpu_id = 7
loglevel = INFO
random_seed = 1
model_id = fine_tuning_ecg_model
preprocessor_id = kerckhoff_basic_preprocessor
evaluator_id = basic_evaluator

[data]
source_id = kerckhoff
leads_to_use = I,II,III,AVR,AVL,AVF,V1,V2,V3,V4,V5,V6
clinical_parameters_outputs = varid_1657
subsampling_window_size = 2000
subsampling_factor = 100
ecg_variants = ecg_raw
snapshot_id = 2020-08-14
dataset_id = 2020-08-14_kerckhoff
metadata_id = 2020-07-02_kerckhoff
split_id = 2020-08-14_kerckhoff_cv_k10_k1
record_ids_excluded = T1_CMR_BN-899

[hyperparameters_general]
number_epochs = 200
optimizer = adam
learning_rate = 0.00001
shuffle = true
loss_function = binary_crossentropy
number_training_repetitions = 20

[evaluation]
metrics = sensitivity,specificity,AUC,DOR
calculation_methods = sample_level,subsample_level
class_names = varid_1657_TRUE
target_metric = AUC
tensorboard_subdir = jul2020
recipients_emails = nils.gumpfer@kite.thm.de
sensitivity_threshold = 0.4
specificity_threshold = 0.4

[transfer_learning]
load_model_experiment_id = 2020-09_ngmp33_transfer_learning_pilot_2__k1_r8
load_model_epoch = 6